---
title: Yet Another Smacof
  - Square Symmetric Case
author: 
      name: Jan de Leeuw
      orcid: 0000-0003-1420-1797
      email: jan@deleeuwpdx.net
      affiliation: 
        - name: University of California Los Angeles
          city: Los Angeles
          state: CA
          url: www.ucla.edu
      license: "CC0"
date: last-modified
date-format: long
bibliography: [mypubs.bib, total.bib]
number-sections: true
pdf-engine: lualatex
keep-tex: true
format:
   pdf:
    fontsize: 12pt
    include-in-header: 
     - preamble.tex
    keep-tex: true
    link-citations: true
    documentclass: scrartcl
    number-sections: true
   html:
    fontsize: 12pt
    include-in-header: 
     - preamble.css
    keep-md: true
    number-sections: true
toc: true
toc-depth: 3
editor: source
papersize: letter
graphics: true
link-citations: true
mainfont: Times New Roman
abstract: We rewrite the metric/nonmetric and weighted/unweighted versions of the smacof program for     square symmetric data as one monolithic C program. R is used for taking care of the data and          parameter setup, the I/O, and of issuing a single call to *.C()* to load the shared library that      does all the computations. This makes this new *smacofSS()* program five to fifty times as fast       (for our examples) as the *smacofSym()* function from the R smacof package. In addition we included    various options to
   accelerate convergence. Utilities for various initial configurations and plots are included in the    package. Examples are included to compare output and time for the R and C versions and to             illustrate the plots and the effect of the various acceleration strategies.
---

```{r loadpackages, echo = FALSE}
suppressPackageStartupMessages(library(knitr, quietly = TRUE))
suppressPackageStartupMessages(library(tinytex, quietly = TRUE))
suppressPackageStartupMessages(library(microbenchmark, quietly = TRUE))
suppressPackageStartupMessages(library(smacof, quietly = TRUE))
```

```{r loadsourses, echo = FALSE}
source("smacofDataUtilities.R")
source("smacofTorgerson.R")
source("smacofGuttman.R")
source("smacofElegant.R")
source("smacofPlots.R")
source("smacofSS.R")
source("smacofSSData/ekmanData.R")
source("smacofSSData/gruijterData.R")
source("smacofSSData/morseData.R")
source("smacofSSData/wishData.R")
```

```{r turnoff, echo = FALSE}
options(warn = -1)
```

**Note:** This is a working manuscript which may be expanded/updated frequently. All suggestions for improvement are welcome. All Rmd, tex, html, pdf, R, and C files are in the public domain. Attribution will be appreciated, but is not required. All files can be found at <https://github.com/deleeuw/smacofFlat>



# Introduction

In Multidimensional Scaling (MDS) we start with $n$ *objects*. Objects can be anything: people, animals, molecules, locations, time points, stimuli, political parties, and so on. We have information about the *similarities* or *dissimilarities* of some or all of the $\binom{n}{2}$ pairs of objects. Say we have information about $m$ dissimilarities $\delta_k$, with $k=1,\cdots m$. Thus each index $k$ refers to a pair of indices $(i,j)$, with $1\leq i\leq n$ and $1\leq j\leq n$. The information is of the form $\delta\in\Delta$, where $\Delta$ is a known subset of the non-negative orthant of $\mathbb{R}^m$. If the dissimilarities are known numbers and $\Delta$ has only a single element the MDS problem is *metric*, in all other cases the problem is *non-metric*.

In MDS we want to map the objects into *points* in $p$-dimensional Euclidean space in such a way that the distances $d_k$ between the points approximate the dissimilarities $\delta_k$.
The quality of the approximation is given by the least squares loss function\footnote{The symbol $:=$ is used for definitions.} \begin{equation}
\sigma(X,\Delta):=\frac{\sum_{k=1}^mw_k(\delta_k-d_k(X))^2}{\sum_{k=1}^mw_k\delta_k^2},
\label{eq-stressdef}
\end{equation} Traditionally, this loss function is called *stress* (@kruskal_64a, @kruskal_64b). It is true that
in Kruskal's paper there are no weights and the sum of squares of the distances is in the denominator. It is
shown in @kruskal_carroll_69, and in more detail in @deleeuw_U_75a, that the solution of the MDS problem
for the different denominators are the same, up a scale constant which is irrelevant for MDS.

In definition \eqref{eq-stressdef}

-   $\delta_k$ are $m$ non-negative *pseudo-distances*;
-   $w_k$ are $m$ positive *weights*;
-   $X$ is an $n\times p$ *configuration*, with coordinates of $n$ *points* in $\mathbb{R}^p$;
-   $d_k(X)$ are the (Euclidean) *distances* between the rows of the configuration matrix.

The (unconstrained, least squares, square, symmetric, Euclidean, $p-$dimensional) MDS problem is to minimize $\sigma$ of \eqref{eq-stressdef} over all $n\times p$ configurations and over the set $\Delta\in\mathbb{R}^m_+$ of non-negative pseudo-distances.

The standard iterative methods for Multidimensional Scaling (MDS), such as *smacof* (@deleeuw_mair_A_09c, @mair_groenen_deleeuw_A_22) and *ALSCAL* (@takane_young_deleeuw_A_77), can be quite slow to converge. Thus there have been various attempts to use standard numerical analysis
techniques to accelerate MDS convergence. But none of these methods, despite of being quite successful, has been implemented in the usual MDS techniques.

@ramsay_75 used multivariate Aitkin acceleration on various problems in psychometrics and statistics. including MDS.
In @groenen_glunt_hayden_96 standard *smacof* iterations were compared with iterations of the
spectral gradient method.
@rosman_bronstein_bronstein_sidi_kimmel_08
@deleeuw_R_06b
@deleeuw_R_08i


@lepage_saucier_24


# MDS Data Structures

Data management and algorithm initialization in *smacofSS()* is handled by R (@r_core_team_25). We start with an R object of class *dist* containing dissimilarities. Here is a small example of order four.

```{r small, echo = FALSE}
small <- as.dist(matrix(
  c(0, 1, 3, 2, 1, 0, 1, 3, 3, 1, 0, 1, 2, 3, 1, 0), 4, 4))
print(small)
```

Turn this into MDS data with the utility *makeMDSData()*, which creates an object of class *smacofSSData*.

```{r smalldata}
smallData <- makeMDSData(small)
print(smallData)
```

Note that the data in column *delta* are increasing, and that *blocks* are *tie-blocks*, i.e. they indicate how many elements are equal to the first element of the block. Also, the *weights* are always there in some form or another, even for MDS analyses that are *unweighted* (i.e. when all $w_k$ are equal). An object of class *smacofSSData* is *complete* if all $\binom{n}{2}$ dissimilarities are present. *makeMDSData()* can handle missing data and nontrivial weights. If our example is

```{r smallmis, echo = FALSE}
smallMissing <- small
smallMissing[1] <- smallMissing[3] <- NA
print(smallMissing) 
```

and we add weights, also of class *dist*,

```{r smallweights, echo = FALSE}
smallWeights <- as.dist(matrix(c(0, 1, 1, 2, 1, 0, 3, 1, 1, 3, 0, 0, 2, 1, 0, 0 ), 4, 4))
print(smallWeights)
```

then our *smacofSSData* object becomes

```{r smalldatamis}
smallData <- makeMDSData(smallMissing, smallWeights)
print(smallData)
```

In the dist objects *delta* and *weights* the missing data are coded as zero weights, or as dissimilarities and/or weights that are *NA*. Zero dissimilarities do not indicate missing data. Thus weights are always strictly positive and missing data do not enter into the data object at all.

These conventions make it possible to also handle rectangular off-diagonal data, such as this *delta* and *weights*.

```{r rect, echo = FALSE}
m <- matrix(c(1, 3, 1, 1, 2, 1, 3, 3, 3, 1, 2, 3), 4, 3)
rect <- matrix(0, 7, 7)
rect[1:4, 5:7] <- m
rect <- as.dist(rect + t(rect))
weights <- matrix(0, 7, 7)
weights[1:4, 5:7] <- 1
weights <- as.dist(weights + t(weights))
print(rect)
print(weights)
```

Now *makeMDSData()* gives

```{r rectdata, echo = FALSE}
rectData <- makeMDSData(rect, weights)
print(rectData)
```

Note however that handling rectangular data with square symmetric MDS is inefficient, and it is better to use smacof programs specifically designed for rectangular data.

It is of course also possible to construct *smacofSSData* objects in other ways, and to edit the objects generated by *makeMDSData()*, for instance by deleting/adding observations or transforming weights/dissimilarities. As long as the conventions are obeyed that no index pair $(i,j)$ occurs more than once, that the dissimilarities remain sorted, and that the tie-blocks faithfully reflect ties in the sorted dissimilarities. We do need $i\neq j$, but it is not necessary that always $i>j$.



# Computation

We minimize stress from \eqref{eq-stressdef} by minimizing its numerator
$\smash{\sum_{k=1}^m w_k(\delta_k-d_k(X))^2}$
over the $n\times p$ configurations $X$ and over $\delta\in\Delta\cap\mathcal{S}$, where $\mathcal{S}$ is set of all vectors in $\mathbb{R}^m$ with $\smash{\sum_{k=1}^mw_k\delta_k^2=1}$. In @deleeuw_U_75a this is called 
*explicit normalization* (of the disparities) to contrast it with the *implicit normalization* in \eqref{eq-stressdef}. It is also shown in @deleeuw_U_75a that explicit and implicit normalization give the
same solution for $\delta$ and $X$ up to a scale constant. See also @bauschke_bui_wang_18.

The default initial configuration for the iterations is the classical scaling solution, with missing data imputed as average non-missing dissimilarities. Smacof algorithms for MDS use *Alternating Least Squares (ALS)* iterations to minimize stress. ALS is a form of block
relaxation applied to least squares loss functions. Specific cases of ALS have been around for a long time. But as
a general class of techniques it was introduced in @deleeuw_R_68d, where it was also given its name.
If there are two blocks of variables we alternate finding the optimum for the variables in the first block, with those in the second block fixed at their current values, and finding the optimum for the variables in the second block, with those in the first block fixed at their new current values. In the terminology of @guttman_68
this strategy defines a *two-phase algorithm*.
ALS is especially relevant for non-metric scaling, in which the two sets of unknowns $X$ and $\delta$ are
nicely separated.

Finding the optimal $X$ for given $\delta$ means solving a metric MDS problem. The vector $\delta$ is
fixed throughout the computations, in other words $\Delta$ is a singleton, a set with one element. To solve
the optimum $X$ subproblem we use *majorization*, which was introduced to MDS by @deleeuw_C_77. The majorization details are now in many places, for example in @borg_groenen_05 or @groenen_vandevelden_16. Although majorization in metric MDS does not use ALS, it is a form of block relaxation (@deleeuw_C_94c) that also proceeds by solving a sequence of relatively  simple least squares problems.

In the non-metric case finding the optimum $\delta$ for fixed $X$, and thus fixed $d(X)$, is a *monotone regression*
problem, i.e. a linear least squares problem with monotonicity constraints on the parameters. There is a huge
literature on monotone regression and the *Pool Adjacent Violators Algorithm (PAVA)* reviewed in @deleeuw_hornik_mair_A_09. In the MDS context it suffices to refer to @kruskal_64b.

In our implementation of smacof we alternate one majorization step with one monotone regression step. Thus
in the first phase we make only one step towards the conditional minimum over $X$, while in the second phase we go all the way to the conditional minimum over $\delta$ . There may be some improvement possible by making more majorization steps in the first phase, or by using the over-relaxation step proposed by @deleeuw_heiser_C_80.
However, these possible accelerations have not been implemented yet.

In the non-metrix case our algorithm is quite different from that in @kruskal_64a, @kruskal_64b. Kruskal 
defines his non-metric stress as
\begin{equation}
\sigma(X):=\min_{\delta\in\Delta}\frac{\sum_{k=1}^mw_k(\delta_k-d_k(X))^2}{\sum_{k=1}^mw_kd_k^2(X)}.
\end{equation}
This stress is a function of $X$ only, which is then minimized by a gradient method with a complicated step-size
procedure. In Guttman's terminology this is a *one-phase* procedure. Even in the metric case Kruskal's
steps differs from smacof's majorization steps, which are gradient
steps with a constant step-size that guarantees monotone convergence to a local minimum from any starting point.

In the code used in this paper *smacofSS()* is an R function in the R front end *smacofSS.R* that reads the parameters and data of the problem and then loads a shared library, called *smacofSSEngine.so*, which contains the compiled code of the C routine *smacofSSEngine()*. The C routine *smacofSSEngine()* alternates calls to the
compiled C routines *smacofSSMajorize()* and *smacofSSMonotone()*. Because of this modularity the same code can be
used with small modifications for alternative MDS methods such as McGee's Elastic Scaling and Sammon Mapping (@deleeuw_E_25f, @deleeuw_E_25g).

The github repository has the R and C code, some utilities in R, and a small Makefile for the shared library.


# Software 

## Arguments

The *smacofSS()* function has the following arguments, with default values,

1.  *theData*, a *smacofSSData* object.
2.  *ndim=2*, dimensionality of MDS analysis.
3.  *xinit=NULL*, initial configuration, NULL or an *nobj* by *ndim* matrix.
4.  *ties = 1*, ties approach, 1, 2, or 3 for primary, secondary, tertiary.
5.  *iord = 2*, acceleration strategy, vector with integers between 0 and 3.
6.  *safe = TRUE*, if TRUE guarantees monotone convergence.
7.  *itmax = 1000*, maximum number of iterations.
8.  *eps = 1e-6*, if successive configurations change less than *eps*, stop.
9.  *digits = 10*, digits stress print if verbose is TRUE,
10. *width = 15*, width stress print if verbose is TRUE,
11. *verbose = TRUE*, TRUE/FALSE print stress for each iteration to *stdout*.
12. *weighted = FALSE*, TRUE/FALSE for weighted/unweighted least squares.
13. *ordinal = FALSE*, FALSE for numerical,TRUE for ordinal.





## Value

The list of objects returned by *smacofSS()* mimics, as much as possible, the list returned by the function
*smacofSym()* from the smacof package.

1.  *delta*, dissimilarities, vector of length $m$.
2.  *dhat*, final pseudo-distances, vector of length $m$.
3.  *confdist*, final distances, vector of length $m$.
4.  *conf*, final configuration, $n\times p$ matrix.
5.  *weightmat*, weights, vector of length $m$.
6.  *stress*, final stress.
7.  *ndim*, number of dimensions.
8.  *init*, initial configuration, $n\times p$ matrix..
9.  *niter*, number of iterations.
10. *nobj*, number of objects.
11. *iind*, row indices, vector of length $m$.
12. *jind*, column indices, vector of length $m$.
13. *weighted*, was the analysis weighted.
14. *ordinal*, was the analysis ordinal (and if so, which tie approach).
15. *ties*, approach to ties if ordinal (one, two, or three).

One important special case should be kept in mind. In the ordinal case with the primary approach to ties, the data are (potentially) reordered within tie blocks in each iteration. In each iteration we have to reorder the indices *iind*, *jind*, and in the weighted case the weights. There is no need to reorder delta and the blocks, because the only ordering changes are within blocks. Ultimately this means that if smacofSS() returns a list, then in that list *iind*, *jind*, and in the weighted case *weightmat* will be ordered differently from the corresponding columns in the MDS data structure. No reordering is going on using the secondary and tertiary approaches.

# Details {#sec-details}

## Interface C and R {#sec-interface}

The C routine *smacofSSEngine()* by itself is a complete smacof MDS programs. It would be easy to write a main program in C that do the same job as the R frontend, and compile it to a stand-alone executable.

The C code uses the *.C()* calling conventions and is otherwise not dependent on R in any way. It is important to note that the *.C()* call from R is only executed one time in a *smacofSS* job, when loading the shared library, and after that there is only compiled code running until the end of the job. In other words, everything done in R is either front-end or back-end, and is only done once. Earlier versions of the R/C program had R also managing the iterations. In each iteration there was a *.C()* call to update the configuration and in the ordinal case an additional *.C()* call to update the pseudo-distances. This turned out to be unsatisfactory, because it did not give enough speedup compared to the *smacofSym()* in the *smacof* package on CRAN (@deleeuw_mair_A_09c, @mair_groenen_deleeuw_A_22).

## Majorization

The majorization updates are of the form $X\leftarrow V^+B(X)X$, where $V$ and $B(X)$ are symmetric
doubly-centered matrices. Matrix $V$ is constant and has off-diagonal elements $-w_{ij}$, matrix $B(X)$
has off-diagonal elements $-w_{ij}\delta_{ij}/d_{ij}(X)$. Matrix $V^+$ is a generalized inverse of $V$. For details see, for example, @deleeuw_heiser_C_80 or @deleeuw_A_88b. If the weights are irreducible,
which we can assume without loss of generality (@deleeuw_C_77), then
\begin{equation}
V^+=(V+\frac{1}{n}ee')^{-1}-\frac{1}{n}ee'
\end{equation}
can be used to efficiently compute the Moore-Penrose inverse. In the unweighted case we can simply set
$\smash{V^+=\frac{1}{n}I}$.

If *weighted* is true then smacof requires two multiplications of dense symmetric matrices of order $n$ in each iteration. This is the most expensive part of the calculations.  We handle these multiplications in the C routine *smacofSSMajorize()*, which is called by *smacofSSEngine()*, by storing and computing only the part below the diagonal and by using double-centering and symmetry in the calculations. The Moore-Penrose inverse
of the weighting matrix $V$ is also needed (only once) and it is computed by the C routine *smacofMPInverseV()* using only the lower diagonal elements of $V$ with symmetric sweeping.

## Monotone Regression {#sec-monotone}

If *ordinal* is TRUE the monotone regression in each iteration uses the C version of the *monotone()* algorithm of @busing_22. The *monotone()* algorithm is called in three separate C routines *primaryApproach()*, *secondaryApproach()*, and *tertiaryApproach()*, for which the code is in *smacofIsotone.c*. One of the three tie approaches is called in each iteration by the *smacofSSMonotone()* routine (which in turn is called by *smacofSSEngine()*).

## Initial Configuration {#sec-initial}

The initial configuration routines are written in R. They are

1.  *smacofTorgerson(theData, ndim)*. Returns initial configuration in $nobj\times ndim$ matrix using classical MDS.
2.  *smacofGuttman(theData, ndim)*. Returns the Guttman-Lingoes initial configuration in $nobj\times ndim$ matrix.
3.  *smacofElegant(theData, ndim)*. Returns the "elegant" initial configuration in $nobj\times ndim$ matrix.

They all need the first *ndim* eigenvalues with the corresponding eigenvalues. We use *eigs-sym()* from the RSpectra
package (@qiu_mei_24) for this. We can also generate a random initial configuration with *smacofRandomConfiguration()* in *smacofAuxiliaries.R*. Random configurations are not really useful for data analysis, but can be used in theoretical studies of convergence and local minima.

Each of the three routines is actually a fairly complete metric MDS program that takes a *smacofSSData* object as its argument and returns a value similar in structure to the *smacofSSResult* object returned by *smacofSS()*. Thus the returned object can be used directly the plotting routines of @sec-plotting.

In terms of strategy we suggest that in an MDS analysis the researcher first computes one or more initial configurations (which are all independent MDS solutions anyway, except for the random configuration), and then give one or more of these initial configurations as the *xinit* argument to *smacofSS()*.

The initial configuration routines all are based on finding a solution with a good value of *sstress*, defined in the same way as stress, but with squared distances and dissimilarities. Thus sstress is \begin{equation}
\sigma(X,\Delta):=\frac{\sum_{k=1}^mw_k(\delta_k^2-d_k^2(X))^2}{\sum_{k=1}^mw_k\delta_k^4}.
\label{eq-sstressdef}
\end{equation} The *smacofSSResult* returned by the initial configuration routines has an sstress value, instead of a stress value. Of source the stress value of the sulution will be revealed when it is used as an initial configuration in *smacofSS()*. Also, when *smacofSSResult* from an sstress routine is used for a Shepardplot, squared distances and squared dhats are plotted against unsquared deltas so the plot has a quadratic shape.

### Torgerson {#sec-torgerson}

The default initial configuration is set to NULL for *smacofSS()*. This is mean to emphasize the importance of choosing an initial configuration. But to make life easier for the user if *xinit* is null, then an initial configuration is computed by the *smacofTorgerson()* routine in *smacofAuxiliaries.R*. *smacofTorgerson()* is classical MDS (@torgerson_58), with the missing dissimilarities imputed using the average non-missing dissimilarity. 

The Torgerson initial configuration works best for complete and unweighted data, but may also be satisfactory for a small number of randomly missing data and for weights that do not vary a great deal. Also remember that in the case of a really bad fit classical MDS may run into the problem of negative eigenvalues. This will give the initial configuration a dimension less than $p$, and since smacof iterations never increase dimensionality this will mean the final configuration will also have dimension less than $p$. Thus the Torgerson initial configuration is unsuitable, for example, for full-dimensional scaling (@deleeuw_groenen_mair_E_16e).

### Guttman {#sec-guttman}

The Guttman-Lingoes initial configuration (@guttman_68), which handles missing data and unequal weights, is provided as *smacofGuttman()*. It is closely related to Hayashi's Quantification Method IV (@takane_77) and unlike the Torgerson method does not have a negative eigenvalue problem.

Write sstress as 
\begin{equation}
\sigma(X)=K-2\sum_{k=1}^mw_k\delta_k^2d_k^2(X)+\sum_{k=1}^mw_kd_k^4(X).
\end{equation}
By homogeneity this is scale-equivalent to maximizing the middle term over all configurations for which the third term is one. The middle term is equal to $\text{tr}\ X'BX$, where $B$ is doubly-centered with off-diagonal
elements $-d_{ij}^2(X)$.
Note that $B$ is positive semi-definite. The third term $\smash{\sum_{k=1}^mw_kd_k^4(X)}$ is a homogeneous quartic in $X$, or equivalently a homogeneous quadratic in the elements of $C=XX'$. In the *elegant* algorithm, discussed in @sec-elegant, we majorize this quadratic to arrive at a simpler unweighted quadratic in $C$. In the Guttman initial configuration we maximize the middle term using the alternative quartic constraint $\text{tr}\ (X'X)^2=\text{tr}\ C^2=1$. Note that the $B$ takes weights and missing data into account, but the normalization constraint does not. The stationary equations are $BX=X(X'X)$ and thus the maximum is attained for $\smash{X=K\Lambda^\frac12}$, where $\Lambda$ are the $p$ dominant eigenvalues of $B$ and $K$ are the corresponding eigenvalues.

### Elegant {#sec-elegant}

Our most expensive initial configuration routine is *smacofElegant()*, which implements an optimized version of De Leeuw's 1975 "elegant" algorithm, as described recently in @deleeuw_E_25c. *smacofElegant()* is a stand-alone iterative metric scaling method, implemented in R. Using *smacofElegant()* means a lot of computation just to obtain an initial configuration for *smacofSS()*. On the other hand it is crucial in MDS to have an initial configuration which is as good as possible, because that is the best guarantee against local minima.

### Full-dimensional Scaling

Finally, we have the option to uses the $p$ dominant dimensions of the *full-dimensiponal* scaling solution as initial configuration. We know that full-dimensional scaling converges to the global minimum of stress in $n-1$ dimensions, and actually to the global minimum for all $p\geq r$, where $r$ is the *Gower rank* of the data (@deleeuw_E_16k). This will provide a good initial estimate if $r$ is close to $p$.

## Acceleration

A *iord* is a vector $\ell$ of $n\geq 1$ integers, with 
$0\leq \ell_i\leq 3$. Strategies are used to code $n$ *updates*,
with update $i$ has *order* $\ell_i$. Iterations repeat
strategies cyclically. Thus iord $(0,0,3)$ means that
iterations use updates of order $(0,0,3,0,0,3,...)$, while 
$(1,0)$ means the order sequence $(1,0,1,0,1,0,...)$.
The theory in @lepage_saucier_24 allows one to go to orders
hgher than three, but we will use these in this paper.

To define orders zero to three for smacof we use the Guttman transform $\Gamma$ of an MDS configuration. In iteration $k$ we compute
\begin{subequations}
\begin{align}
\Delta_0^{(k)}&:=X^{(k)},\\
\Delta_1^{(k)}&:=\Gamma(X^{(k)})-X^{(k)},\\
\Delta_2^{(k)}&:=\Gamma^2(X^{(k)})-2\Gamma(X^{(k)})+X^{(k)},\\
\Delta_3^{(k)}&:=\Gamma^3(X^{(k)})-3\Gamma^2(X^{(k)})+3\Gamma(X^{(k)})-X^{(k)}.
\end{align}
\end{subequations}
0. Order zero are the standard smacof iterations
\begin{equation}
X^{(k+1)}=\Gamma(X^{(k)}).
\end{equation}
1. For order one
\begin{subequations}
\begin{align}
\lambda_1^{(k)}&:=\frac{\langle\Delta_0^{(k)},\Delta_1^{(k)}\rangle}{\langle\Delta_1^{(k)},\Delta_1^{(k)}\rangle},\\
X^{(k+1)}&=\Delta_0^{(k)}+\lambda_1^{(k)}\Delta_1^{(k)}.
\end{align}
\end{subequations}
2. For order two
\begin{subequations}
\begin{align}
\lambda_2^{(k)}&:=\frac{\langle\Delta_1^{(k)},\Delta_2^{(k)}\rangle}{\langle\Delta_2^{(k)},\Delta_2^{(k)}\rangle},\\
X^{(k+1)}&=\Delta_0^{(k)}+2\lambda_2^{(k)}\Delta_1^{(k)}+\left[\lambda_2^{(k)}\right]^2\Delta_2^{(k)}.
\end{align}
\end{subequations}
3. For order three
\begin{subequations}
\begin{align}
\lambda_3^{(k)}&:=\frac{\langle\Delta_2^{(k)},\Delta_3^{(k)}\rangle}{\langle\Delta_3^{(k)},\Delta_3^{(k)}\rangle},\\
X^{(k+1)}&=\Delta_0^{(k)}+3\lambda_3^{(k)}\Delta_1^{(k)}+3\left[\lambda_3^{(k)}\right]^2\Delta_2^{(k)}+
\left[\lambda_3^{(k)}\right]^3\Delta_3^{(k)}.
\end{align}
\end{subequations}

# Utilities

## Data Utilities

There are four functions in smacofDataUtilities.R

1.  *makeMDSData(delta, weights = NULL)*. Returns *smacofSSData* object from dist objects.
2.  *fromMDSData(theData)*. Returns *dist* objects of dissimilarities and weights from *smacofSSData* object.
3.  *matrixPrint(x, digits = 6, width = 8, format = "f", flag = "+")*. Formats and prints a matrix.
4.  *smacofRandomConfiguration(theData, ndim = 2)*. Random initial configuration.

## Plotting {#sec-plotting}

There are three plot routines in the file *smacofPlots.R*.

1.  *smacofShepardPlot(h, main = "ShepardPlot", fitlines = TRUE, colline = "RED", colpoint = "BLUE", resolution = 100, lwd = 2, cex = 1, pch = 16)*
2.  *smacofConfigurationPlot(h, main = "ConfigurationPlot", labels = NULL, dim1 = 1, dim2 = 2, pch = 16, col = "RED", cex = 1)*
3.  *smacofDistDhatPlot(h, fitlines = TRUE, colline = "RED", colpoint = "BLUE", main = "Dist-Dhat Plot", cex = 1, lwd = 2, pch = 16)*

The Shepard plot has the original dissimilarities on the horizontal axis, and both the pseudo-distances and the distances on the vertical axis. Pseudo-distances are plotted as points of color *colline*, and are connected by a line of color *colline*. Distances are plotted as points if color *colpoint*. If *fitlines* is TRUE then black vertical lines from the distance point to the pseudo-distance point are drawn.

The configuration plot plots two dimensions *dim1* and *dim2* of the configuration. If *labels* is NULL points are drawn with symbol *pch*, otherwise a vector of labels is used.

A DistDhat-plot has distances on the horizontal axis and pseudo-distances on the vertical axes. Points are drawn using symbol *pch* in color *colpoint*. The line through the origin with slope one is drawn in color *colline*. If *fitlines* is true then black lines from the points to their orthogonal projections on the line are drawn.

Residual plot

## Newton


# Example Data Sets

There are a number of example data sets in the directory smacofSSData. They are mostly of the 20th century boomer type: small and collected from the aggregated judgments of human subjects. All data are available both as dist objects and as MDS data structures. The Wish and Iris data are not used in our computations but are included as examples of MDS data structures.

## Ekman Data

Similarity data between 14 colors from @ekman_54. Rating scale similarity judgments averaged over subjects, linearly converted to unit interval dissimilarities.

## Morse Data

Dissimilarity between the Morse codes of 36 letters and numbers from @rothkopf_57. Confusion probabilities transformed to dissimilarities.

## Gruijter Data

Dissimilarities of nine Dutch political parties in 1967, from @degruijter_67. Collected using the method of triads and averaged over 100 subjects.

## Wish Data

Rating scale similarities between 12 nations, collected by @wish_71. Averaged over subjects, subtracted from maximum scale value to form dissimilarities.

## Iris Data

Classical iris data from @anderson_36 via @fisher_36. Euclidean distances over four measurements on 150 irises.



# Comparisons

## Initial

In this section we use the Ekman and Gruijter data to compare the three different initial configurations. Parameters are all set at defaults, which means a two-dimensional solution with unweighted and numerical options.

```{r einitial, echo = FALSE, cache = TRUE}
h1 <- smacofSS(ekmanData, ndim = 2, xinit = smacofTorgerson(ekmanData, ndim = 2)$conf)
h2 <- smacofSS(ekmanData, ndim = 2, xinit = smacofGuttman(ekmanData, ndim = 2)$conf)
h3 <- smacofSS(ekmanData, ndim = 2, xinit = smacofElegant(ekmanData, ndim = 2, verbose = FALSE)$conf)
```

We start with the Ekman data, which have a very good fit in two dimensions. From the Torgerson initial configuration we need `r h1$niter` iterations to converge to stress `r h1$stress`. From the Guttman initial configuration stress is `r h2$stress` after `r h2$niter` iterations. And from elegant we use `r h3$niter` iterations to arrive at `r h3$stress`.

```{r ginitial, echo = FALSE, cache = TRUE}
h1 <- smacofSS(gruijterData, ndim = 2, xinit = smacofTorgerson(gruijterData, ndim = 2)$conf)
h2 <- smacofSS(gruijterData, ndim = 2, xinit = smacofGuttman(gruijterData, ndim = 2)$conf)
h3 <- smacofSS(gruijterData, ndim = 2, xinit = smacofElegant(gruijterData, ndim = 2, verbose = FALSE)$conf)
```

We repeat this for the Gruijter data, which have a poor fit in two dimensions. From the Torgerson initial configuration we need `r h1$niter` iterations to converge to stress `r h1$stress`. From the Guttman initial configuration stress is `r h2$stress` after `r h2$niter` iterations. And from elegant we use `r h3$niter` iterations to arrive at `r h3$stress`.

For both Ekman and Gruijter it seems that smacofSS() arrives at the same solution, no matter which initial configuration we use. There is some small difference in the number of iterations that are required, and it seems the Torgerson initial configuration holds its own. *smacofElegant()* is expensive and does not seem to deliver any extra efficiency. So, on the basis of the limited experience reported here, we do not recommend it for general use.

## Outcome

In this section we compare the output (final stress, number of iterations) of smacofSym() and smacofSS() using the Ekman and Morse data. Note that smacofSym() reports the square root of the final stress, following @kruskal_64a, so for comparison purposes we square it again. All runs are started with the two-dimensional Torgerson solution and have the stop criteria *eps* equal to `r 1e-10` and *itmax* equal to 1000 (except when using the tertiary approach when *itmax* is 10000). In the weighted case the weights for Ekman are $w_k=\delta_k^2$, for Morse they are $w_k=\delta_k^{-1}$.

```{r somedataE, echo = FALSE}
source("smacofSSData/ekmanData.R")
xinit <- smacofTorgerson(ekmanData, 2)$conf
```

```{r compURE, cache = TRUE, echo = FALSE}
h1 <- smacofSym(ekman, init = xinit, type = "ratio", eps = 1e-10, itmax = 1000)
h2 <- smacofSS(ekmanData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, verbose = FALSE, weighted = FALSE, ordinal = FALSE)
vecUR <- c(h1$stress ^ 2, h1$niter, h2$stress, h2$niter)
```

```{r compUO1E, cache = TRUE, echo = FALSE}
h1 <- smacofSym(ekman, init = xinit, type = "ordinal", ties = "primary", eps = 1e-10, itmax = 1000)
h2 <- smacofSS(ekmanData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, ties = 1, verbose = FALSE, weighted = FALSE, ordinal = TRUE)
vecUO1 <- c(h1$stress ^ 2, h1$niter, h2$stress, h2$niter)
```

```{r compUO2E, cache = TRUE, echo = FALSE}
h1 <- smacofSym(ekman, init = xinit, type = "ordinal", ties = "secondary", eps = 1e-10, itmax = 1000)
h2 <- smacofSS(ekmanData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, ties = 2, verbose = FALSE, weighted = FALSE, ordinal = TRUE)
vecUO2 <- c(h1$stress ^ 2, h1$niter, h2$stress, h2$niter)
```

```{r compUO3E, cache = TRUE, echo = FALSE}
h1 <- smacofSym(ekman, init = xinit, type = "ordinal", ties = "tertiary", eps = 1e-10, itmax = 10000)
h2 <- smacofSS(ekmanData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 10000, ties = 3, verbose = FALSE, weighted = FALSE, ordinal = TRUE)
vecUO3 <- c(h1$stress ^ 2, h1$niter, h2$stress, h2$niter)
```

```{r compWRE, cache = TRUE, echo = FALSE}
h1 <- smacofSym(ekman, type = "ratio", eps = 1e-10, weightmat = ekman ^ 2, itmax = 1000)
h2 <- smacofSS(ekmanData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, verbose = FALSE, weighted = TRUE, ordinal = FALSE)
vecWR <- c(h1$stress ^ 2, h1$niter, h2$stress, h2$niter)
```

```{r compWO1E, cache = TRUE, echo = FALSE}
h1 <- smacofSym(ekman, init = xinit, type = "ordinal", ties = "primary", weightmat = ekman ^ 2, eps = 1e-10, itmax = 1000)
h2 <- smacofSS(ekmanData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, ties = 1, verbose = FALSE, weighted = TRUE, ordinal = TRUE)
vecWO1 <- c(h1$stress ^ 2, h1$niter, h2$stress, h2$niter)
```

```{r compWO2E, cache = TRUE, echo = FALSE}
h1 <- smacofSym(ekman, init = xinit, type = "ordinal", ties = "secondary", weightmat = ekman ^ 2, eps = 1e-10, itmax = 1000)
h2 <- smacofSS(ekmanData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, ties = 2, verbose = FALSE, weighted = TRUE, ordinal = TRUE)
vecWO2 <- c(h1$stress ^ 2, h1$niter, h2$stress, h2$niter)
```

```{r compWO3E, cache = TRUE, echo = FALSE}
h1 <- smacofSym(ekman, init = xinit, type = "ordinal", ties = "tertiary", weightmat = ekman ^ 2, eps = 1e-10, itmax = 10000)
h2 <- smacofSS(ekmanData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 10000, ties = 3, verbose = FALSE, weighted = TRUE, ordinal = TRUE)
vecWO3 <- c(h1$stress ^ 2, h1$niter, h2$stress, h2$niter)
```

```{r compkableE, echo = FALSE}
x <- matrix(c(vecUR, vecUO1, vecUO2, vecUO3, vecWR, vecWO1, vecWO2, vecWO3), 8, 4, byrow = TRUE)
r <- c("unweighted numerical", 
       "unweighted ordinal ties = 1",
       "unweighted ordinal ties = 2",
       "unweighted ordinal ties = 3",
       "weighted numerical", 
       "weighted ordinal ties = 1",
       "weighted ordinal ties = 2",
       "weighted ordinal ties = 3"
)
row.names(x) <- r
r <- c("Sym stress", "Sym niter", "SS stress", "SS niter")
colnames(x) <- r
kable(x, format = "simple", align = NULL, row.names = TRUE, caption = "Comparison smacofSym() and smacofSS() results Ekman data")
```

```{r somedata, echo = FALSE}
source("smacofSSData/morseData.R")
xinit <- smacofTorgerson(morseData, 2)$conf
```

```{r compUR, cache = TRUE, echo = FALSE}
h1 <- smacofSym(morse, init = xinit, type = "ratio", eps = 1e-10, itmax = 1000)
h2 <- smacofSS(morseData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, verbose = FALSE, ordinal = FALSE, weighted = FALSE)
vecUR <- c(h1$stress ^ 2, h1$niter, h2$stress, h2$niter)
```

```{r compUO1, cache = TRUE, echo = FALSE}
h1 <- smacofSym(morse, init = xinit, type = "ordinal", ties = "primary", eps = 1e-10, itmax = 1000)
h2 <- smacofSS(morseData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, ties = 1, verbose = FALSE, ordinal = TRUE, weighted = FALSE)
vecUO1 <- c(h1$stress ^ 2, h1$niter, h2$stress, h2$niter)
```

```{r compUO2, cache = TRUE, echo = FALSE}
h1 <- smacofSym(morse, init = xinit, type = "ordinal", ties = "secondary", eps = 1e-10, itmax = 1000)
h2 <- smacofSS(morseData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, ties = 2, verbose = FALSE, ordinal = TRUE, weighted = FALSE)
vecUO2 <- c(h1$stress ^ 2, h1$niter, h2$stress, h2$niter)
```

```{r compUO3, cache = TRUE, echo = FALSE}
h1 <- smacofSym(morse, init = xinit, type = "ordinal", ties = "tertiary", eps = 1e-10, itmax = 1000)
h2 <- smacofSS(morseData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, ties = 3, verbose = FALSE, ordinal = TRUE, weighted = FALSE)
vecUO3 <- c(h1$stress ^ 2, h1$niter, h2$stress, h2$niter)
```

```{r compWR, cache = TRUE, echo = FALSE}
h1 <- smacofSym(morse, type = "ratio", eps = 1e-10, weightmat = 1 / morse, itmax = 1000)
h2 <- smacofSS(morseData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, verbose = FALSE, ordinal = FALSE, weighted = TRUE)
vecWR <- c(h1$stress ^ 2, h1$niter, h2$stress, h2$niter)
```

```{r compWO1, cache = TRUE, echo = FALSE}
h1 <- smacofSym(morse, init = xinit, type = "ordinal", ties = "primary", weightmat = 1 / morse, eps = 1e-10, itmax = 1000)
h2 <- smacofSS(morseData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, ties = 1, verbose = FALSE, ordinal = TRUE, weighted = TRUE)
vecWO1 <- c(h1$stress ^ 2, h1$niter, h2$stress, h2$niter)
```

```{r compWO2, cache = TRUE, echo = FALSE}
h1 <- smacofSym(morse, init = xinit, type = "ordinal", ties = "secondary", weightmat = 1 / morse, eps = 1e-10, itmax = 1000)
h2 <- smacofSS(morseData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, ties = 2, verbose = FALSE, ordinal = TRUE, weighted = TRUE)
vecWO2 <- c(h1$stress ^ 2, h1$niter, h2$stress, h2$niter)
```

```{r compWO3, cache = TRUE, echo = FALSE}
h1 <- smacofSym(morse, init = xinit, type = "ordinal", ties = "tertiary", weightmat = 1 / morse, eps = 1e-10, itmax = 1000)
h2 <- smacofSS(morseData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, ties = 3, verbose = FALSE, ordinal = TRUE, weighted = TRUE)
vecWO3 <- c(h1$stress ^ 2, h1$niter, h2$stress, h2$niter)
```

```{r compkable, echo = FALSE}
x <- matrix(c(vecUR, vecUO1, vecUO2, vecUO3, vecWR, vecWO1, vecWO2, vecWO3), 8, 4, byrow = TRUE)
r <- c("unweighted numerical", 
       "unweighted ordinal ties = 1",
       "unweighted ordinal ties = 2",
       "unweighted ordinal ties = 3",
       "weighted numerical", 
       "weighted ordinal ties = 1",
       "weighted ordinal ties = 2",
       "weighted ordinal ties = 3"
)
row.names(x) <- r
r <- c("Sym stress", "Sym niter", "SS stress", "SS niter")
colnames(x) <- r
kable(x, format = "simple", align = NULL, row.names = TRUE, caption = "Comparison smacofSym() and smacofSS() results Morse data")
```

The conclusion is clear. For both the Ekman and the Morse example the results of *smacofSym()* and *smacofSS()* are identical. Not only the final stress (and thus presumably the final configuration) but also the number of iterations (and thus presumably all iterations). This boosts our confidence in the correctness of both programs.

## Time

The *microbenchmark* package (@mersmann_24) is mainly intended to time small pieces of code, not complete programs. Nevertheless we will use it to compare *smacofSym()* and *smacofSS()*, until something more appropriate (and equally easy to use) comes along. We again use the Ekman and Morse data with default options. From the microbenchmark output we find the median time over 100 runs each of the two programs.

```{r microbenchmark_numE, cache = TRUE, echo = FALSE}
h <- microbenchmark(
smacofSym(ekman, type = "ratio", eps = 1e-10, itmax = 1000),
smacofSS(ekmanData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, verbose = FALSE, ordinal = FALSE, weighted = FALSE), control = list(order = "inorder"))
hss <- median(h$time[2 * (1:100)])
hsy <- median(h$time[-2 * (1:100)])
vecUR <- c(hss, hsy, hsy/hss)
```

```{r microbenchmark_ord1E, cache = TRUE, echo = FALSE}
h <- microbenchmark(
smacofSym(ekman, type = "ordinal", ties = "primary", eps = 1e-10, itmax = 1000),
smacofSS(ekmanData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, ties = 1, verbose = FALSE, ordinal = TRUE, weighted = FALSE), control = list(order = "inorder"))
hss <- median(h$time[2 * (1:100)])
hsy <- median(h$time[-2 * (1:100)])
vecUO1 <- c(hss, hsy, hsy/hss)
```

```{r microbenchmark_ord2E, cache = TRUE, echo = FALSE}
h <- microbenchmark(
smacofSym(ekman, type = "ordinal", ties = "secondary", eps = 1e-10, itmax = 1000),
smacofSS(ekmanData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, ties = 2, verbose = FALSE, ordinal = TRUE, weighted = FALSE), control = list(order = "inorder"))
hss <- median(h$time[2 * (1:100)])
hsy <- median(h$time[-2 * (1:100)])
vecUO2 <- c(hss, hsy, hsy/hss)
```

```{r microbenchmark_ord3E, cache = TRUE, echo = FALSE}
h <- microbenchmark(
smacofSym(ekman, type = "ordinal", ties = "tertiary", eps = 1e-10, itmax = 10000),
smacofSS(ekmanData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 10000, ties = 3, verbose = FALSE, ordinal = TRUE, weighted = FALSE), control = list(order = "inorder"))
hss <- median(h$time[2 * (1:100)])
hsy <- median(h$time[-2 * (1:100)])
vecUO3 <- c(hss, hsy, hsy/hss)
```

```{r wgthnumE, cache = TRUE, echo = FALSE}
h <- microbenchmark(
smacofSym(ekman, type = "ratio", eps = 1e-10, weightmat = ekman ^ 2, itmax = 1000),
smacofSS(ekmanData, ndim = 2,  xinit = xinit, eps = 1e-10, itmax = 1000, verbose = FALSE, ordinal = FALSE, weighted = TRUE), control = list(order = "inorder"))
hss <- median(h$time[2 * (1:100)])
hsy <- median(h$time[-2 * (1:100)])
vecWR <- c(hss, hsy, hsy/hss)
```

```{r wgthord1E, cache = TRUE, echo = FALSE}
h <- microbenchmark(
smacofSym(ekman, type = "ordinal", ties = "primary", eps = 1e-10, weightmat = ekman ^ 2, itmax = 1000),
smacofSS(ekmanData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, ties = 1, verbose = FALSE, ordinal = TRUE, weighted = TRUE), control = list(order = "inorder"))
hss <- median(h$time[2 * (1:100)])
hsy <- median(h$time[-2 * (1:100)])
vecWO1 <- c(hss, hsy, hsy/hss)
```

```{r wgthord2E, cache = TRUE, echo = FALSE}
h <- microbenchmark(
smacofSym(ekman, type = "ordinal", ties = "secondary", eps = 1e-10, weightmat = ekman ^ 2, itmax = 1000),
smacofSS(
  ekmanData,
  ndim = 2,
  xinit = xinit,
  eps = 1e-10,
  itmax = 1000,
  ties = 2,
  verbose = FALSE, ordinal = TRUE, weighted = TRUE
), control = list(order = "inorder"))
hss <- median(h$time[2 * (1:100)])
hsy <- median(h$time[-2 * (1:100)])
vecWO2 <- c(hss, hsy, hsy/hss)
```

```{r wgthord3E, cache = TRUE, echo = FALSE}
h <- microbenchmark(
smacofSym(ekman, type = "ordinal", ties = "tertiary", eps = 1e-10, weightmat = ekman ^ 2, itmax = 10000),
smacofSS(ekmanData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 10000, ties = 3, verbose = FALSE, ordinal = TRUE, weighted = TRUE), control = list(order = "inorder"))
hss <- median(h$time[2 * (1:100)])
hsy <- median(h$time[-2 * (1:100)])
vecWO3 <- c(hss, hsy, hsy/hss)
```

```{r timekableE, echo = FALSE}
x <- matrix(c(vecUR, vecUO1, vecUO2, vecUO3, vecWR, vecWO1, vecWO2, vecWO3), 8, 3, byrow = TRUE)
r <- c("unweighted numerical", 
       "unweighted ordinal ties = 1",
       "unweighted ordinal ties = 2",
       "unweighted ordinal ties = 3",
       "weighted numerical", 
       "weighted ordinal ties = 1",
       "weighted ordinal ties = 2",
       "weighted ordinal ties = 3"
)
row.names(x) <- r
r <- c("SS time", "Sym time", "ratio Sym/SS")
colnames(x) <- r
kable(x, format = "simple", align = NULL, row.names = TRUE, caption = "Comparison smacofSym() and smacofSS() running times Ekman Data")
```

The entries in the table for the tertiary approach are suspect, because tertiary uses a huge number of iterations to arrive at a perfect solution. In some of the microbenchmark runs it may actually use the full 10000 iterations. From the better conditioned numerical and ordinal solutions we see that *smacofSS()* is between 10 and 55 times as fast as *smacofSym()*. 

```{r microbenchmark_num, cache = TRUE, echo = FALSE}
h <- microbenchmark(
smacofSym(morse, type = "ratio", eps = 1e-10, itmax = 1000),
smacofSS(morseData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, verbose = FALSE , ordinal = FALSE, weighted = FALSE), control = list(order = "inorder"))
hss <- median(h$time[2 * (1:100)])
hsy <- median(h$time[-2 * (1:100)])
vecUR <- c(hss, hsy, hsy/hss)
```

```{r microbenchmark_ord1, cache = TRUE, echo = FALSE}
h <- microbenchmark(
smacofSym(morse, type = "ordinal", ties = "primary", eps = 1e-10, itmax = 1000),
smacofSS(morseData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, ties = 1, verbose = FALSE, ordinal = TRUE, weighted = FALSE), control = list(order = "inorder"))
hss <- median(h$time[2 * (1:100)])
hsy <- median(h$time[-2 * (1:100)])
vecUO1 <- c(hss, hsy, hsy/hss)
```

```{r microbenchmark_ord2, cache = TRUE, echo = FALSE}
h <- microbenchmark(
smacofSym(morse, type = "ordinal", ties = "secondary", eps = 1e-10, itmax = 1000),
smacofSS(morseData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, ties = 2, verbose = FALSE, ordinal = TRUE, weighted = FALSE), control = list(order = "inorder"))
hss <- median(h$time[2 * (1:100)])
hsy <- median(h$time[-2 * (1:100)])
vecUO2 <- c(hss, hsy, hsy/hss)
```

```{r microbenchmark_ord3, cache = TRUE, echo = FALSE}
h <- microbenchmark(
smacofSym(morse, type = "ordinal", ties = "tertiary", eps = 1e-10, itmax = 1000),
smacofSS(morseData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, ties = 3, verbose = FALSE, ordinal = TRUE, weighted = FALSE), control = list(order = "inorder"))
hss <- median(h$time[2 * (1:100)])
hsy <- median(h$time[-2 * (1:100)])
vecUO3 <- c(hss, hsy, hsy/hss)
```

```{r wgthnum, cache = TRUE, echo = FALSE}
h <- microbenchmark(
smacofSym(morse, type = "ratio", eps = 1e-10, weightmat = 1 / morse, itmax = 1000),
smacofSS(morseData, ndim = 2,  xinit = xinit, eps = 1e-10, itmax = 1000, verbose = FALSE, ordinal = FALSE, weighted = TRUE), control = list(order = "inorder"))
hss <- median(h$time[2 * (1:100)])
hsy <- median(h$time[-2 * (1:100)])
vecWR <- c(hss, hsy, hsy/hss)
```

```{r wgthord1, cache = TRUE, echo = FALSE}
h <- microbenchmark(
smacofSym(morse, type = "ordinal", ties = "primary", eps = 1e-10, weightmat = 1 / morse, itmax = 1000),
smacofSS(morseData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, ties = 1, verbose = FALSE, ordinal = TRUE, weighted = TRUE), control = list(order = "inorder"))
hss <- median(h$time[2 * (1:100)])
hsy <- median(h$time[-2 * (1:100)])
vecWO1 <- c(hss, hsy, hsy/hss)
```

```{r wgthord2, cache = TRUE, echo = FALSE}
h <- microbenchmark(
smacofSym(morse, type = "ordinal", ties = "secondary", eps = 1e-10, weightmat = 1 / morse, itmax = 1000),
smacofSS(
  morseData,
  ndim = 2,
  xinit = xinit,
  eps = 1e-10,
  itmax = 1000,
  ties = 2,
  verbose = FALSE, ordinal = TRUE, weighted = TRUE
), control = list(order = "inorder"))
hss <- median(h$time[2 * (1:100)])
hsy <- median(h$time[-2 * (1:100)])
vecWO2 <- c(hss, hsy, hsy/hss)
```

```{r wgthord3, cache = TRUE, echo = FALSE}
h <- microbenchmark(
smacofSym(morse, type = "ordinal", ties = "tertiary", eps = 1e-10, weightmat = 1 / morse, itmax = 1000),
smacofSS(morseData, ndim = 2, xinit = xinit, eps = 1e-10, itmax = 1000, ties = 3, verbose = FALSE, ordinal = TRUE, weighted = TRUE), control = list(order = "inorder"))
hss <- median(h$time[2 * (1:100)])
hsy <- median(h$time[-2 * (1:100)])
vecWO3 <- c(hss, hsy, hsy/hss)
```

```{r timekable, echo = FALSE}
x <- matrix(c(vecUR, vecUO1, vecUO2, vecUO3, vecWR, vecWO1, vecWO2, vecWO3), 8, 3, byrow = TRUE)
r <- c("unweighted numerical", 
       "unweighted ordinal ties = 1",
       "unweighted ordinal ties = 2",
       "unweighted ordinal ties = 3",
       "weighted numerical", 
       "weighted ordinal ties = 1",
       "weighted ordinal ties = 2",
       "weighted ordinal ties = 3"
)
row.names(x) <- r
r <- c("SS time", "Sym time", "ratio Sym/SS")
colnames(x) <- r
kable(x, format = "simple", align = NULL, row.names = TRUE, caption = "Comparison smacofSym() and smacofSS() running times Morse data")
```

```{r iristime, cache = TRUE, echo = FALSE, eval= FALSE}
source("smacofSSData/irisData.R")
h1 <- microbenchmark(
smacofSym(irisDist, eps = 1e-10, verbose = FALSE, type = "ratio", itmax = 1000),
smacofSSUR(irisData, verbose = FALSE))
h2 <- microbenchmark(
smacofSym(irisDist, eps = 1e-10, verbose = FALSE, type = "ordinal", ties = "primary", itmax = 1000),
smacofSSUO(irisData, verbose = FALSE))
```

We see that for the Morse data *smacofSS()* is 3 to 15 times faster than *smacofSym()*. The difference is largest in the numerical case, and it is also larger for unweighted than for weighted. Strangely enough for the ordinal options the weighted case is faster than the corresponding non-weighted case, although a majorization iteration in the weighted case is more expensive. This is undoubtedly because the outcome results in the previous section show that fewer iterations are used in the weighted case. We also see that secondary is faster than primary and tertiary (which is rather well-behaved in the Morse example) is faster than secondary. 

We see that (in these examples) the ratio of execution times for *smacofSym()* and *smacofSS()* is larger for the smaller example. We verify this for the Iris example, which has 11175
dissimilarities. For unweighted/numerical the Sym/SS ratio is 2.5, for unweighted/ordinal
it is 1.06. Execution times are influenced by many factors. In the majorization step *smacofSym()* uses full matrices, which is wasteful in terms of storage, but allows access to the efficient matrix multiplication routines in R (which are already in compiled C code). *smacofSS()* has the more flexible *smacofSSData* structure, which requires less storage but more index manipulation. Both *smacofSym()* and *smacofSS()* use efficient monotone regression routines in C, so the more time the programs spend in the monotone regression step the more equal execution times will be. A reasonable hypothesis is that using *smacofSSData* will be
relatively advantageous if there are many missing data and if there are weights. But 
more precise profiling will be a worthwhile future project.

The two examples are very different because Ekman has an excellent fit, while Morse has a much poorer one. In both
examples the tertiary approach to ties leads to a perfect fit in Ekman and a near perfect fit in Morse. Morse (630 dissimilarities) is quite a bit bigger than Ekman (91 dissimilarities) and Morse has more ties (68 tie-blocks of average size about 9) than Ekman (47 tie-blocks of average size about 2). Except for tertiary Morse requires considerably more iterations than Ekman.

Note, by the way, that we have used microbenchmark in such a way that smacofSS() is always run after the corresponding smacofSym(), and that the eight different basic combinations or weighted and ordinal are always run in the same order.

# Comparing Strategies

In this section we compare the strategies $(x)$ and $(0,x)$, where $x$
is one of 0,1,2,3. Of course iord $(0)$ is identical to iord
$(0,0)$, because both implement a sequence of ordinary smacof iterations. In addition we vary the *safe* parameter.


## Data

## Number of Iterations

We iterate a maximum of 1000 times and we stop if the sup-norm $\|X^{(k+1)}-X^{(k)}\|_\infty$ is less than  $10^{-6}$. This is a much stricter stop citerium as the one used in *smacof*, which stops if the change in loss function value 
$\sigma^{(k)}-\sigma^{(k+1)}$ is less than 
$10^{-6}$. We always start with the classical scaling (Torgerson-Gower) solution.


### Strategy (x)

```{r xF, cache = TRUE, echo = FALSE}
he0 <- smacofSS(ekmanData, iord = 0, verbose = FALSE, safe = FALSE)
he1 <- smacofSS(ekmanData, iord = 1, verbose = FALSE, safe = FALSE)
he2 <- smacofSS(ekmanData, iord = 2, verbose = FALSE, safe = FALSE)
he3 <- smacofSS(ekmanData, iord = 3, verbose = FALSE, safe = FALSE)
hg0 <- smacofSS(gruijterData, iord = 0, verbose = FALSE, safe = FALSE)
hg1 <- smacofSS(gruijterData, iord = 1, verbose = FALSE, safe = FALSE)
hg2 <- smacofSS(gruijterData, iord = 2, verbose = FALSE, safe = FALSE)
hg3 <- smacofSS(gruijterData, iord = 3, verbose = FALSE, safe = FALSE)
hm0 <- smacofSS(morseData, iord = 0, verbose = FALSE, safe = FALSE)
hm1 <- smacofSS(morseData, iord = 1, verbose = FALSE, safe = FALSE)
hm2 <- smacofSS(morseData, iord = 2, verbose = FALSE, safe = FALSE)
hm3 <- smacofSS(morseData, iord = 3, verbose = FALSE, safe = FALSE)
hF<-matrix(c(he0$niter, he1$niter, he2$niter, he3$niter,
        hg0$niter, hg1$niter, hg2$niter, hg3$niter,
        hm0$niter, hm1$niter, hm2$niter, hm3$niter
        ), 3, 4, byrow = TRUE)
row.names(hF) <- c("ekmanData", "gruijterData", "morseData")
```

```{r kxF, echo = FALSE, tab.align = "center"}
kable(hF, row.names = TRUE, col.names = c("(0)", "(1)", "(2)", "(3)"),
      caption = "iord (x), safe = FALSE")
```

```{r xT, cache = TRUE, echo = FALSE}
he0 <- smacofSS(ekmanData, iord = 0, verbose = FALSE, safe = TRUE)
he1 <- smacofSS(ekmanData, iord = 1, verbose = FALSE, safe = TRUE)
he2 <- smacofSS(ekmanData, iord = 2, verbose = FALSE, safe = TRUE)
he3 <- smacofSS(ekmanData, iord = 3, verbose = FALSE, safe = TRUE)
hg0 <- smacofSS(gruijterData, iord = 0, verbose = FALSE, safe = TRUE)
hg1 <- smacofSS(gruijterData, iord = 1, verbose = FALSE, safe = TRUE)
hg2 <- smacofSS(gruijterData, iord = 2, verbose = FALSE, safe = TRUE)
hg3 <- smacofSS(gruijterData, iord = 3, verbose = FALSE, safe = TRUE)
hm0 <- smacofSS(morseData, iord = 0, verbose = FALSE, safe = TRUE)
hm1 <- smacofSS(morseData, iord = 1, verbose = FALSE, safe = TRUE)
hm2 <- smacofSS(morseData, iord = 2, verbose = FALSE, safe = TRUE)
hm3 <- smacofSS(morseData, iord = 3, verbose = FALSE, safe = TRUE)
hT<-matrix(c(he0$niter, he1$niter, he2$niter, he3$niter,
        hg0$niter, hg1$niter, hg2$niter, hg3$niter,
        hm0$niter, hm1$niter, hm2$niter, hm3$niter
        ), 3, 4, byrow = TRUE)
row.names(hT) <- c("ekmanData", "gruijterData", "morseData")
```

```{r kxT, echo = FALSE, tab.align = "center"}
kable(hT, row.names = TRUE, col.names = c("(0)", "(1)", "(2)", "(3)"),
      caption = "iord (x), safe = TRUE")
```

### Strategy (0,x)

```{r 0xF, cache = TRUE, echo = FALSE}
he1 <- smacofSS(ekmanData, iord = c(0,1), verbose = FALSE, safe = FALSE)
he2 <- smacofSS(ekmanData, iord = c(0,2), verbose = FALSE, safe = FALSE)
he3 <- smacofSS(ekmanData, iord = c(0,3), verbose = FALSE, safe = FALSE)
hg1 <- smacofSS(gruijterData, iord = c(0,1), verbose = FALSE, safe = FALSE)
hg2 <- smacofSS(gruijterData, iord = c(0,2), verbose = FALSE, safe = FALSE)
hg3 <- smacofSS(gruijterData, iord = c(0,3), verbose = FALSE, safe = FALSE)
hm1 <- smacofSS(morseData, iord = c(0,1), verbose = FALSE, safe = FALSE)
hm2 <- smacofSS(morseData, iord = c(0,2), verbose = FALSE, safe = FALSE)
hm3 <- smacofSS(morseData, iord = c(0,3), verbose = FALSE, safe = FALSE)
h<-matrix(c(he0$niter, he1$niter, he2$niter, he3$niter,
        hg0$niter, hg1$niter, hg2$niter, hg3$niter,
        hm0$niter, hm1$niter, hm2$niter, hm3$niter
        ), 3, 4, byrow = TRUE)
row.names(h) <- c("ekmanData", "gruijterData", "morseData")
```

```{r k0xF, echo = FALSE, tab.align = "center"}
kable(h, row.names = TRUE, col.names = c("(0,0)", "(0,1)", "(0,2)", "(0,3)"),
      caption = "iord (0,x), safe = FALSE")
```


```{r 0xT, cache = TRUE, echo = FALSE}
he1 <- smacofSS(ekmanData, iord = c(0,1), verbose = FALSE, safe = TRUE)
he2 <- smacofSS(ekmanData, iord = c(0,2), verbose = FALSE, safe = TRUE)
he3 <- smacofSS(ekmanData, iord = c(0,3), verbose = FALSE, safe = TRUE)
hg1 <- smacofSS(gruijterData, iord = c(0,1), verbose = FALSE, safe = TRUE)
hg2 <- smacofSS(gruijterData, iord = c(0,2), verbose = FALSE, safe = TRUE)
hg3 <- smacofSS(gruijterData, iord = c(0,3), verbose = FALSE, safe = TRUE)
hm1 <- smacofSS(morseData, iord = c(0,1), verbose = FALSE, safe = TRUE)
hm2 <- smacofSS(morseData, iord = c(0,2), verbose = FALSE, safe = TRUE)
hm3 <- smacofSS(morseData, iord = c(0,3), verbose = FALSE, safe = TRUE)
h<-matrix(c(he0$niter, he1$niter, he2$niter, he3$niter,
        hg0$niter, hg1$niter, hg2$niter, hg3$niter,
        hm0$niter, hm1$niter, hm2$niter, hm3$niter
        ), 3, 4, byrow = TRUE)
row.names(h) <- c("ekmanData", "gruijterData", "morseData")
```

```{r k0xT, echo = FALSE, tab.align = "center"}
kable(h, row.names = TRUE, col.names = c("(0,0)", "(0,1)", "(0,2)", "(0,3)"),
      caption = "iord (0,x), safe = TRUE")
```

## Timing

### Strategy (x)

```{r mxF, echo = FALSE, cache = TRUE}
suppressWarnings(
h <- microbenchmark(
smacofSS(ekmanData, iord = 0, verbose = FALSE, safe = FALSE),
smacofSS(ekmanData, iord = 1, verbose = FALSE, safe = FALSE),
smacofSS(ekmanData, iord = 2, verbose = FALSE, safe = FALSE),
smacofSS(ekmanData, iord = 3, verbose = FALSE, safe = FALSE),
smacofSS(gruijterData, iord = 0, verbose = FALSE, safe = FALSE),
smacofSS(gruijterData, iord = 1, verbose = FALSE, safe = FALSE),
smacofSS(gruijterData, iord = 2, verbose = FALSE, safe = FALSE),
smacofSS(gruijterData, iord = 3, verbose = FALSE, safe = FALSE),
smacofSS(morseData, iord = 0, verbose = FALSE, safe = FALSE),
smacofSS(morseData, iord = 1, verbose = FALSE, safe = FALSE),
smacofSS(morseData, iord = 2, verbose = FALSE, safe = FALSE),
smacofSS(morseData, iord = 3, verbose = FALSE, safe = FALSE)))
```

```{r pxFR, echo = FALSE, tab.align = "center"}
mh <- matrix(c(1964,57315,537,532, 
               32028, 27371, 2218,3527,
               33178,56410,3547,4445), 3, 4, byrow = TRUE)
row.names(mh) <- c("ekmanData", "gruijterData", "morseData")
kable(mh, row.names = TRUE, col.names = c("(0)", "(1)", "(2)", "(3)"),
      caption = "iord (x), safe = FALSE, language = R")
```
```{r pxFC, echo = FALSE, tab.align = "center"}
mh <- matrix(c(270,834,258,258, 
               207, 481, 145,151,
               1886,3821,1498,1515), 3, 4, byrow = TRUE)
row.names(mh) <- c("ekmanData", "gruijterData", "morseData")
kable(mh, row.names = TRUE, col.names = c("(0)", "(1)", "(2)", "(3)"),
      caption = "iord (x), safe = FALSE, language = C")
```

```{r mxT, echo = FALSE, cache = TRUE}
suppressWarnings(h <- microbenchmark(
smacofSS(ekmanData, iord = 0, verbose = FALSE, safe = TRUE),
smacofSS(ekmanData, iord = 1, verbose = FALSE, safe = TRUE),
smacofSS(ekmanData, iord = 2, verbose = FALSE, safe = TRUE),
smacofSS(ekmanData, iord = 3, verbose = FALSE, safe = TRUE),
smacofSS(gruijterData, iord = 0, verbose = FALSE, safe = TRUE),
smacofSS(gruijterData, iord = 1, verbose = FALSE, safe = TRUE),
smacofSS(gruijterData, iord = 2, verbose = FALSE, safe = TRUE),
smacofSS(gruijterData, iord = 3, verbose = FALSE, safe = TRUE),
smacofSS(morseData, iord = 0, verbose = FALSE, safe = TRUE),
smacofSS(morseData, iord = 1, verbose = FALSE, safe = TRUE),
smacofSS(morseData, iord = 2, verbose = FALSE, safe = TRUE),
smacofSS(morseData, iord = 3, verbose = FALSE, safe = TRUE)))
```
```{r pxTR, echo = FALSE, tab.align = "center"}
mh <- matrix(c(1974,1080,535,526, 
               32564,24020,2089,2575,
               32841,23130,3222,4190), 3, 4, byrow = TRUE)
row.names(mh) <- c("ekmanData", "gruijterData", "morseData")
kable(mh, row.names = TRUE, col.names = c("(0)", "(1)", "(2)", "(3)"),
      caption = "iord (x), safe = TRUE, language = R")
```
```{r pxTC, echo = FALSE, tab.align = "center"}
mh <- matrix(c(283,273,266,266, 
               228,192,156,157,
               2187,1847,1552,1554), 3, 4, byrow = TRUE)
row.names(mh) <- c("ekmanData", "gruijterData", "morseData")
kable(mh, row.names = TRUE, col.names = c("(0)", "(1)", "(2)", "(3)"),
      caption = "iord (x), safe = TRUE, language = C")
```
### Strategy (0,x)

```{r m0xF, cache = TRUE, echo = FALSE}
suppressWarnings(h <- microbenchmark(
smacofSS(ekmanData, iord = c(0,1), verbose = FALSE, safe = FALSE),
smacofSS(ekmanData, iord = c(0,2), verbose = FALSE, safe = FALSE),
smacofSS(ekmanData, iord = c(0,3), verbose = FALSE, safe = FALSE),
smacofSS(gruijterData, iord = c(0,1), verbose = FALSE, safe = FALSE),
smacofSS(gruijterData, iord = c(0,2), verbose = FALSE, safe = FALSE),
smacofSS(gruijterData, iord = c(0,3), verbose = FALSE, safe = FALSE),
smacofSS(morseData, iord = c(0,1), verbose = FALSE, safe = FALSE),
smacofSS(morseData, iord = c(0,2), verbose = FALSE, safe = FALSE),
smacofSS(morseData, iord = c(0,3), verbose = FALSE, safe = FALSE)))
```
```{r p0xFR, echo = FALSE, tab.align = "center"}
mh <- matrix(c(1467,584,656,
               26266,2910,2543,
               26074,4162,4028), 3, 3, byrow = TRUE)
row.names(mh) <- c("ekmanData", "gruijterData", "morseData")
kable(mh, row.names = TRUE, col.names = c("(0,1)", "(0,2)", "(0,3)"),
      caption = "iord (0,x), safe = FALSE, language = R")
```
```{r p0xFC, echo = FALSE, tab.align = "center"}
mh <- matrix(c(275,270,270,
               192,156,158,
               1730,1496,1521), 3, 3, byrow = TRUE)
row.names(mh) <- c("ekmanData", "gruijterData", "morseData")
kable(mh, row.names = TRUE, col.names = c("(0,1)", "(0,2)", "(0,3)"),
      caption = "iord (0,x), safe = FALSE, language = C")
```

```{r m0xT, cache = TRUE, echo = FALSE}
suppressWarnings(h <- microbenchmark(
smacofSS(ekmanData, iord = c(0,1), verbose = FALSE, safe = TRUE),
smacofSS(ekmanData, iord = c(0,2), verbose = FALSE, safe = TRUE),
smacofSS(ekmanData, iord = c(0,3), verbose = FALSE, safe = TRUE),
smacofSS(gruijterData, iord = c(0,1), verbose = FALSE, safe = TRUE),
smacofSS(gruijterData, iord = c(0,2), verbose = FALSE, safe = TRUE),
smacofSS(gruijterData, iord = c(0,3), verbose = FALSE, safe = TRUE),
smacofSS(morseData, iord = c(0,1), verbose = FALSE, safe = TRUE),
smacofSS(morseData, iord = c(0,2), verbose = FALSE, safe = TRUE),
smacofSS(morseData, iord = c(0,3), verbose = FALSE, safe = TRUE)))
```
```{r p0xTR, echo = FALSE, tab.align = "center"}
mh <- matrix(c(1466,584,654,25584,2544,2795,25898,4103,3986), 3, 3, byrow = TRUE)
row.names(mh) <- c("ekmanData", "gruijterData", "morseData")
kable(mh, row.names = TRUE, col.names = c("(0,1)", "(0,2)", "(0,3)"),
      caption = "iord (0,x), safe = TRUE, language = R")
```
```{r p0xTC, echo = FALSE, tab.align = "center"}
mh <- matrix(c(268,264,263,190,145,149,1936,1549,1542), 3, 3, byrow = TRUE)
row.names(mh) <- c("ekmanData", "gruijterData", "morseData")
kable(mh, row.names = TRUE, col.names = c("(0,1)", "(0,2)", "(0,3)"),
      caption = "iord (0,x), safe = TRUE, language = C")
```

## Nonmetric

```{r xFN, cache = TRUE, echo = FALSE}
he0 <- smacofSS(ekmanData, iord = 0, verbose = FALSE, safe = TRUE, ordinal = TRUE)
he1 <- smacofSS(ekmanData, iord = 1, verbose = FALSE, safe = TRUE, ordinal = TRUE)
he2 <- smacofSS(ekmanData, iord = 2, verbose = FALSE, safe = TRUE, ordinal = TRUE)
he3 <- smacofSS(ekmanData, iord = 3, verbose = FALSE, safe = TRUE, ordinal = TRUE)
hg0 <- smacofSS(gruijterData, iord = 0, verbose = FALSE, safe = TRUE, ordinal = TRUE)
hg1 <- smacofSS(gruijterData, iord = 1, verbose = FALSE, safe = TRUE, ordinal = TRUE)
hg2 <- smacofSS(gruijterData, iord = 2, verbose = FALSE, safe = TRUE, ordinal = TRUE)
hg3 <- smacofSS(gruijterData, iord = 3, verbose = FALSE, safe = TRUE, ordinal = TRUE)
hm0 <- smacofSS(morseData, iord = 0, verbose = FALSE, safe = TRUE, ordinal = TRUE)
hm1 <- smacofSS(morseData, iord = 1, verbose = FALSE, safe = TRUE, ordinal = TRUE)
hm2 <- smacofSS(morseData, iord = 2, verbose = FALSE, safe = TRUE, ordinal = TRUE)
hm3 <- smacofSS(morseData, iord = 3, verbose = FALSE, safe = TRUE, ordinal = TRUE)
hF<-matrix(c(he0$niter, he1$niter, he2$niter, he3$niter,
        hg0$niter, hg1$niter, hg2$niter, hg3$niter,
        hm0$niter, hm1$niter, hm2$niter, hm3$niter
        ), 3, 4, byrow = TRUE)
row.names(hF) <- c("ekmanData", "gruijterData", "morseData")
```

```{r kxFN, echo = FALSE, tab.align = "center"}
kable(hF, row.names = TRUE, col.names = c("(0)", "(1)", "(2)", "(3)"),
      caption = "Nonmetric, iord (x), safe = TRUE")
```

```{r m0xTN, cache = TRUE, echo = FALSE}
suppressWarnings(h <- microbenchmark(
smacofSS(ekmanData, iord = 0, verbose = FALSE, safe = TRUE, ordinal = TRUE),
smacofSS(ekmanData, iord = 1, verbose = FALSE, safe = TRUE, ordinal = TRUE),
smacofSS(ekmanData, iord = 2, verbose = FALSE, safe = TRUE, ordinal = TRUE),
smacofSS(ekmanData, iord = 3, verbose = FALSE, safe = TRUE, ordinal = TRUE),
smacofSS(gruijterData, iord = 0, verbose = FALSE, safe = TRUE, ordinal = TRUE),
smacofSS(gruijterData, iord = 1, verbose = FALSE, safe = TRUE, ordinal = TRUE),
smacofSS(gruijterData, iord = 2, verbose = FALSE, safe = TRUE, ordinal = TRUE),
smacofSS(gruijterData, iord = 3, verbose = FALSE, safe = TRUE, ordinal = TRUE),
smacofSS(morseData, iord = 0, verbose = FALSE, safe = TRUE, ordinal = TRUE),
smacofSS(morseData, iord = 1, verbose = FALSE, safe = TRUE, ordinal = TRUE),
smacofSS(morseData, iord = 2, verbose = FALSE, safe = TRUE, ordinal = TRUE),
smacofSS(morseData, iord = 3, verbose = FALSE, safe = TRUE, ordinal = TRUE)
))
```

```{r p0xTRN, echo = FALSE, tab.align = "center"}
mh <- matrix(c(1071,532,604,629,962,586,584,573,4022,2842, 2298, 2297), 3, 4, byrow = TRUE)
row.names(mh) <- c("ekmanData", "gruijterData", "morseData")
kable(mh, row.names = TRUE, col.names = c("(0)", "(1)", "(2)", "(3)"),
      caption = "Nonmetric, iord (x), safe = TRUE")
```

# Plots

To show some plots we repeat eight possible analyses (numeric/ordinal, where ordinal has three tie approaches, and weighted/unweighted) using the Ekman and Morse data. The number of iterations and the final stress have already been reported in the comparisons section. Both data sets have a fairly large number of ties, so we expect the choice of the ties approach to have some effect.

The next eight pages have Shepard plots and DistDhat plots for each of the four unweighted analyses. No plots are given for the weighted analyses, because they would illustrate essentially the same points. We made the plots large so they show some detail. Shepard plots have *fitlines* equal to TRUE, DistDhat plots have *fitlines* equal to TRUE for the Ekman data and FALSE for the Morse data. The sum of the squared lengths of the vertical fitlines in the Shepard plots is the stress. In the DistDhat plots the sum of squares of distances of the points to their orthogonal projections on the line is also the stress. Thus we can see from the plots where the largest residuals are, although the plot does not show which pair of points the fitlines correspond with. That information can easily be obtained from the numerical output.

The Ekman example has an exceptionally good fit, even in the numerical case. Still, allowing for ordinal transformations gives a major improvement. Especially the DistDhat plots in the ordinal case show the different ways of handling tie blocks. The tertiary approach gives what is essentially a perfect fit, but the Shepard plot shows that in order to achieve this deviations from monotonicity are required.

The Morse example has a bad numerical fit, and the improvements by the ordinal options are huge. There are no fitlines in the DistDhat plots, because that would mainly result in big black blobs. As in the Ekman example the tertiary approach gives close to perfect fit, at the cost of many deviations from monotonicity.

```{r ekmanall, echo = FALSE, cache = TRUE}
source("smacofSSData/ekmanData.R")
xinit <- smacofTorgerson(ekmanData, 2)$conf
hUR <- smacofSS(ekmanData, xinit = xinit, ordinal = FALSE, weighted = FALSE, ties = 1, verbose = FALSE)
hUO1 <- smacofSS(ekmanData, xinit = xinit, ordinal = TRUE, weighted = FALSE, ties = 1, verbose = FALSE)
hUO2 <- smacofSS(ekmanData, xinit = xinit, ordinal = TRUE, weighted = FALSE, ties = 2, verbose = FALSE)
hUO3 <- smacofSS(ekmanData, xinit = xinit, ordinal = TRUE, weighted = FALSE, ties = 3, verbose = FALSE)
hWR <- smacofSS(ekmanData, xinit = xinit, ordinal = FALSE, weighted = TRUE, verbose = FALSE)
hWO1 <- smacofSS(ekmanData, xinit = xinit, ordinal = TRUE, weighted = TRUE, ties = 1, verbose = FALSE)
hWO2 <- smacofSS(ekmanData, xinit = xinit, ordinal = TRUE, weighted = TRUE, ties = 2, verbose = FALSE)
hWO3 <- smacofSS(ekmanData, xinit = xinit, ordinal = TRUE, weighted = TRUE, ties = 3, verbose = FALSE)
```



```{r plotekman, fig.align = "center", fig.width = 8, fig.height = 8, echo = FALSE}
par(pty="s")
smacofShepardPlot(hUR, main = "Shepard Plot, Ekman Data, Unweighted, Numerical")
smacofShepardPlot(hUO1, main = "Shepard Plot, Ekman Data, Unweighted, Ordinal, Primary")
smacofShepardPlot(hUO2, main = "Shepard Plot, Ekman Data, Unweighted, Ordinal, Secondary")
smacofShepardPlot(hUO3, main = "Shepard Plot, Ekman Data, Unweighted, Ordinal, Tertiary")
smacofDistDhatPlot(hUR, main = "DistDhat Plot, Ekman Data, Unweighted, Numerical")
smacofDistDhatPlot(hUO1, main = "DistDhat Plot, Ekman Data, Unweighted, Ordinal, Primary")
smacofDistDhatPlot(hUO2, main = "DistDhat Plot, Ekman Data, Unweighted, Ordinal, Secondary")
smacofDistDhatPlot(hUO3,  main = "DistDhat Plot, Ekman Data, Unweighted, Ordinal, Tertiary")
```

```{r morseall, echo = FALSE, cache = TRUE}
source("smacofSSData/morseData.R")
xinit <- smacofTorgerson(morseData, 2)$conf
hUR <- smacofSS(morseData, xinit = xinit, ordinal = FALSE, weighted = FALSE, verbose = FALSE)
hUO1 <- smacofSS(morseData, xinit = xinit, ordinal = TRUE, weighted = FALSE, ties = 1, verbose = FALSE)
hUO2 <- smacofSS(morseData, xinit = xinit, ordinal = TRUE, weighted = FALSE, ties = 2, verbose = FALSE)
hUO3 <- smacofSS(morseData, xinit = xinit, ordinal = TRUE, weighted = FALSE, ties = 3, verbose = FALSE)
hWR <- smacofSS(morseData, xinit = xinit, ordinal = FALSE, weighted = TRUE, verbose = FALSE)
hWO1 <- smacofSS(morseData, xinit = xinit, ordinal = TRUE, weighted = TRUE, ties = 1, verbose = FALSE)
hWO2 <- smacofSS(morseData, xinit = xinit, ordinal = TRUE, weighted = TRUE, ties = 2, verbose = FALSE)
hWO3 <- smacofSS(morseData, xinit = xinit, ordinal = TRUE, weighted = TRUE, ties = 3, verbose = FALSE)
```



```{r plotmorse, fig.align = "center", fig.width = 8, fig.height = 8, echo = FALSE}
par(pty="s")
smacofShepardPlot(hUR, main = "Shepard Plot, Morse Data, Unweighted, Numerical")
smacofShepardPlot(hUO1, main = "Shepard Plot, Morse Data, Unweighted, Ordinal, Primary")
smacofShepardPlot(hUO2, main = "Shepard Plot, Morse Data, Unweighted, Ordinal, Secondary")
smacofShepardPlot(hUO3, main = "Shepard Plot, Morse Data, Unweighted, Ordinal, Tertiary")
smacofDistDhatPlot(hUR, fitlines = FALSE, main = "DistDhat Plot, Morse Data, Unweighted, Numerical")
smacofDistDhatPlot(hUO1, fitlines = FALSE, main = "DistDhat Plot, Morse Data, Unweighted, Ordinal, Primary")
smacofDistDhatPlot(hUO2, fitlines = FALSE, main = "DistDhat Plot, Morse Data, Unweighted, Ordinal, Secondary")
smacofDistDhatPlot(hUO3, fitlines = FALSE, main = "DistDhat Plot, Morse Data, Unweighted, Ordinal, Tertiary")
```



# References
